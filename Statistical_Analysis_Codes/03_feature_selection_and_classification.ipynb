{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1fd3cab5",
            "metadata": {},
            "source": [
                "# 03_feature_selection_and_classification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "08605998",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
                "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.feature_selection import mutual_info_classif\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from catboost import CatBoostClassifier\n",
                "\n",
                "DATA_PATH = r\"c:/Users/asus/OneDrive/Desktop/ITML Project/processed_data/symbolized_data.csv\"\n",
                "OUTPUT_DIR = r\"c:/Users/asus/OneDrive/Desktop/ITML Project/results\"\n",
                "PLOTS_DIR = r\"c:/Users/asus/OneDrive/Desktop/ITML Project/plots\"\n",
                "MODELS_DIR = r\"c:/Users/asus/OneDrive/Desktop/ITML Project/models\"\n",
                "\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
                "os.makedirs(MODELS_DIR, exist_ok=True)\n",
                "\n",
                "def compute_transition_matrix(sequence, n_states=8):\n",
                "    transitions = np.zeros((n_states, n_states))\n",
                "    for (i, j) in zip(sequence[:-1], sequence[1:]):\n",
                "        transitions[i, j] += 1\n",
                "    transitions += 1e-5\n",
                "    row_sums = transitions.sum(axis=1)\n",
                "    return transitions / row_sums[:, np.newaxis]\n",
                "\n",
                "def compute_stationary_distribution(P):\n",
                "    eigvals, eigvecs = np.linalg.eig(P.T)\n",
                "    idx = np.argmin(np.abs(eigvals - 1))\n",
                "    pi = np.real(eigvecs[:, idx])\n",
                "    return pi / pi.sum()\n",
                "\n",
                "def main():\n",
                "    print(\"Loading data...\")\n",
                "    df = pd.read_csv(DATA_PATH)\n",
                "    \n",
                "    # Feature Engineering: Markov-based Likelihoods\n",
                "    print(\"Engineering Markov features...\")\n",
                "    classes = df['device_class'].unique()\n",
                "    n_states = 8\n",
                "    \n",
                "    class_models = {}\n",
                "    for cls in classes:\n",
                "        cls_seq = df[df['device_class'] == cls]['symbol'].values\n",
                "        P = compute_transition_matrix(cls_seq, n_states)\n",
                "        pi = compute_stationary_distribution(P)\n",
                "        class_models[cls] = {'P': P, 'pi': pi}\n",
                "        \n",
                "    # Feature: log(P(symbol | class)) = log(pi_class[symbol])\n",
                "    for cls in classes:\n",
                "        pi = class_models[cls]['pi']\n",
                "        log_pi = np.log(pi + 1e-10)\n",
                "        df[f'log_lik_{cls}'] = df['symbol'].map(lambda s: log_pi[s])\n",
                "        \n",
                "    # Prepare Data\n",
                "    drop_cols = ['device_class', 'filename', 'device', 'symbol']\n",
                "    X = df.drop(columns=drop_cols).fillna(0)\n",
                "    y = df['device_class']\n",
                "    \n",
                "    le = LabelEncoder()\n",
                "    y_encoded = le.fit_transform(y)\n",
                "    \n",
                "    # Feature Selection (Mutual Information)\n",
                "    print(\"Performing Feature Selection...\")\n",
                "    mi_scores = mutual_info_classif(X, y_encoded, random_state=42)\n",
                "    mi_df = pd.DataFrame({'Feature': X.columns, 'MI_Score': mi_scores}).sort_values(by='MI_Score', ascending=False)\n",
                "    \n",
                "    print(\"\\nTop 10 Features:\\n\", mi_df.head(10))\n",
                "    mi_df.to_csv(os.path.join(OUTPUT_DIR, 'feature_importance_mi.csv'), index=False)\n",
                "    \n",
                "    plt.figure(figsize=(10, 8))\n",
                "    sns.barplot(data=mi_df.head(20), x='MI_Score', y='Feature', palette='viridis')\n",
                "    plt.title('Top 20 Features by Mutual Information')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(os.path.join(PLOTS_DIR, 'mi_feature_importance.png'))\n",
                "    plt.close()\n",
                "    \n",
                "    # Select Top K Features\n",
                "    top_k = 20\n",
                "    top_features = mi_df['Feature'].head(top_k).tolist()\n",
                "    X_selected = X[top_features]\n",
                "    print(f\"Selected top {top_k} features.\")\n",
                "    \n",
                "    # Classification\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
                "    \n",
                "    models = {\n",
                "        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
                "        'CatBoost': CatBoostClassifier(verbose=0, random_state=42)\n",
                "    }\n",
                "    \n",
                "    results = {}\n",
                "    \n",
                "    for name, model in models.items():\n",
                "        print(f\"Training {name}...\")\n",
                "        model.fit(X_train, y_train)\n",
                "        y_pred = model.predict(X_test)\n",
                "        acc = accuracy_score(y_test, y_pred)\n",
                "        results[name] = acc\n",
                "        print(f\"{name} Accuracy: {acc:.4f}\")\n",
                "        \n",
                "        cm = confusion_matrix(y_test, y_pred)\n",
                "        plt.figure(figsize=(10, 8))\n",
                "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
                "        plt.title(f'Confusion Matrix - {name}')\n",
                "        plt.ylabel('True Label')\n",
                "        plt.xlabel('Predicted Label')\n",
                "        plt.tight_layout()\n",
                "        plt.savefig(os.path.join(PLOTS_DIR, f'confusion_matrix_{name}.png'))\n",
                "        plt.close()\n",
                "        \n",
                "    # Stacking\n",
                "    print(\"Training Stacking Classifier...\")\n",
                "    estimators = [\n",
                "        ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
                "        ('cat', CatBoostClassifier(verbose=0, random_state=42))\n",
                "    ]\n",
                "    stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
                "    stacking_clf.fit(X_train, y_train)\n",
                "    y_pred_stack = stacking_clf.predict(X_test)\n",
                "    acc_stack = accuracy_score(y_test, y_pred_stack)\n",
                "    results['Stacking'] = acc_stack\n",
                "    print(f\"Stacking Accuracy: {acc_stack:.4f}\")\n",
                "    \n",
                "    results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])\n",
                "    results_df.to_csv(os.path.join(OUTPUT_DIR, 'classification_results.csv'), index=False)\n",
                "    \n",
                "    plt.figure(figsize=(8, 6))\n",
                "    sns.barplot(data=results_df, x='Model', y='Accuracy', palette='magma')\n",
                "    plt.title('Classification Accuracy Comparison')\n",
                "    plt.ylim(0, 1.0)\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(os.path.join(PLOTS_DIR, 'model_comparison.png'))\n",
                "    plt.close()\n",
                "    \n",
                "    print(\"Classification complete.\")\n",
                "\n",
                "main()"
            ]
        }
    ],
    "metadata": {},
    "nbformat": 4,
    "nbformat_minor": 5
}